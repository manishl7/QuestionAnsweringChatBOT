# -*- coding: utf-8 -*-
"""qa_huggingfacelibrary.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HVIR-1DjcTnrvEWHbhHues8SHdjPS4e4
"""

#ERROR ENCOUNTERD : dropout(): argument 'input' (position 1) must be Tensor, not str With Bert
#FIX :
!pip install transformers==3

import torch
import transformers

from transformers import BertForQuestionAnswering

model=BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')

tokenizer=transformers.BertTokenizer.from_pretrained('bert-base-uncased')

a='''
Your password will be reset
We take security very seriously at Daraz. If you’re a tech guru & you have found an issue which has a real world impact, you can report it to us via Live Chat (7am to 9pm Sunday to Friday and 9am to 9pm Saturday) with these details: Steps to reproduce the bug/issue, Your web browser/mobile browser’s name and version Screenshot/screencast (if any)"
If you think that your Intellectual Property Right has been infringed by any of our sellers, you can contact us via Live Chat from 7am to 9 pm Sunday to Friday and 9am to 9pm Saturday."
If you think that your Intellectual Property Right has been infringed by any of our sellers, you can contact us via Live Chat from 7am to 9 pm Sunday to Friday and 9am to 9pm Saturday."
Daraz First Games was the new and funOnline Gaming Platformwhere users were able to play Arcade'''
import textwrap
wrapper=textwrap.TextWrapper(width=170)
a=wrapper.fill(a)



def answer_question(question,answer_text):
    
    input_ids=tokenizer.encode(question,answer_text)
    print(f"Query has {len(input_ids)} tokens")
    
    #setting segment ids
    sep_index=input_ids.index(tokenizer.sep_token_id)
    
    #no of a segments
    num_seg_a=sep_index+1
    #no of b segments
    num_seb_b=len(input_ids)-num_seg_a
    
    #constructing list of 0's and 1's 
    segment_ids=[0]*num_seg_a +[1]*num_seb_b
    #making sure there is segment id of every single token
    assert len(segment_ids)==len(input_ids)
    
    #evaluating our question through model
    start_scores,end_scores=model(torch.tensor([input_ids]), # token repn of input text 
                                 token_type_ids=torch.tensor([segment_ids]))#segment ids to seperate A and B
    
    #Generating answer i.e Finding tokens with higest 'start' & 'end' scores
    answer_start=torch.argmax(start_scores)
    answer_end=torch.argmax(end_scores)
    
    #getting ip's string
    tokens=tokenizer.convert_ids_to_tokens(input_ids)
    #starting with first token
    answer=tokens[answer_start]
    #selecting remaining answers,tokens and joining them with white space
    for i in range(answer_start+1,answer_end+1):
        #if its a subword;we'll recombine it with previous tokens
        if tokens[i][0:2]=='##':
            answer+=tokens[i][2:]
        #else add a space to the token
        else:
            answer+=' '+tokens[i]
    print(f"Answer : {answer}")
    
q1="Can we chat with you ?"
q2="is arcade game available? "
answer_question(q1,a)



















































































